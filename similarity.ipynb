{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aAoIzcaKg9jzsDQBvSooSum0N0nO8rzH",
      "authorship_tag": "ABX9TyPLZEOHh3P0KzRCQUN0Njzf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binchen1998/similar/blob/main/similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3yWOustIau5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "cd3bbfbd-309d-4195-bf6d-d628aac16704"
      },
      "source": [
        "#################################################\n",
        "# Imports and function definitions\n",
        "#################################################\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For saving 'feature vectors' into a txt file\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "\n",
        "# Time for measuring the process time\n",
        "import time\n",
        "\n",
        "# Glob for reading file names in a folder\n",
        "import glob\n",
        "import os.path\n",
        "\n",
        "List1 = []\n",
        "List2 = []\n",
        "List3 = []\n",
        "List4 = []\n",
        "#################################################\n",
        "\n",
        "#################################################\n",
        "# This function:\n",
        "# Loads the JPEG image at the given path\n",
        "# Decodes the JPEG image to a uint8 W X H X 3 tensor\n",
        "# Resizes the image to 224 x 224 x 3 tensor\n",
        "# Returns the pre processed image as 224 x 224 x 3 tensor\n",
        "#################################################\n",
        "def load_img(path):\n",
        "\n",
        "  # Reads the image file and returns data type of string\n",
        "  img = tf.io.read_file(path)\n",
        "\n",
        "  # Decodes the image to W x H x 3 shape tensor with type of uint8\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "\n",
        "  # Resize the image to 224 x 244 x 3 shape tensor\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "\n",
        "  # Converts the data type of uint8 to float32 by adding a new axis\n",
        "  # This makes the img 1 x 224 x 224 x 3 tensor with the data type of float32\n",
        "  # This is required for the mobilenet model we are using\n",
        "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "  return img\n",
        "\n",
        "#################################################\n",
        "# This function:\n",
        "# Loads the mobilenet model in TF.HUB\n",
        "# Makes an inference for all images stored in a local folder\n",
        "# Saves each of the feature vectors in a file\n",
        "#################################################\n",
        "def get_image_feature_vectors():\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  print(\"---------------------------------\")\n",
        "  print (\"Step.1 of 2 - mobilenet_v2_140_224 - Loading Started at %s\" %time.ctime())\n",
        "  print(\"---------------------------------\")\n",
        "\n",
        "  # Definition of module with using tfhub.dev handle\n",
        "  module_handle = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" \n",
        "  \n",
        "  # Load the module\n",
        "  module = hub.load(module_handle)\n",
        "\n",
        "  print(\"---------------------------------\")\n",
        "  print (\"Step.1 of 2 - mobilenet_v2_140_224 - Loading Completed at %s\" %time.ctime())\n",
        "  print(\"--- %.2f minutes passed ---------\" % ((time.time() - start_time)/60))\n",
        " \n",
        "    # Loads and pre-process the image\n",
        "  img1 = load_img('/content/test/square.jpg')\n",
        "  img2 = load_img('/content/test/square2.jpg')\n",
        "  img3 = load_img('/content/test/square3.jpg')\n",
        "  img4 = load_img('/content/test/square4.jpg')\n",
        "\n",
        "  # Calculate the image feature vector of the img\n",
        "  features1 = module(img1) \n",
        "  features2 = module(img2) \n",
        "  features3 = module(img3) \n",
        "\n",
        "  #print(features)  \n",
        "\n",
        "  # Remove single-dimensional entries from the 'features' array\n",
        "  List1 = np.squeeze(features1)\n",
        "  List2 = np.squeeze(features2)\n",
        "  List3 = np.squeeze(features3)  \n",
        "  List4 = np.squeeze(module(load_img('/content/test/square4.jpg')))\n",
        "  List5 = np.squeeze(module(load_img('/content/test/square5.jpg')))\n",
        "  result = 1 - spatial.distance.cosine(List5, List1)\n",
        "  print(result)\n",
        "  \n",
        "  return\n",
        "\n",
        "get_image_feature_vectors()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Step.1 of 2 - mobilenet_v2_140_224 - Loading Started at Wed Oct 13 13:30:12 2021\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "Step.1 of 2 - mobilenet_v2_140_224 - Loading Completed at Wed Oct 13 13:30:15 2021\n",
            "--- 0.04 minutes passed ---------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9130802aa195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mget_image_feature_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-9130802aa195>\u001b[0m in \u001b[0;36mget_image_feature_vectors\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Loads and pre-process the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m   \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test/square.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m   \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test/square2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test/square3.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9130802aa195>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m# Reads the image file and returns data type of string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m# Decodes the image to W x H x 3 shape tensor with type of uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m       return read_file_eager_fallback(\n\u001b[0;32m--> 556\u001b[0;31m           filename, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    557\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0;32m--> 579\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    580\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /content/test/square.jpg; No such file or directory [Op:ReadFile]"
          ]
        }
      ]
    }
  ]
}